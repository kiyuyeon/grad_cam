{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["DEBUG = True"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import sys\n","sys.path = [\n","    '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master',\n","] + sys.path"]},{"cell_type":"markdown","metadata":{},"source":["DISCLAIMER: The libraries are imported at different points in the code for better organization and readability, \n","following the logical flow of the code and to facilitate the development process. This allows also for\n","better management of dependencies. It also allows to have clearer separation of concerns and facilitate the understanding of the code's\n","purpose and functionality."]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import skimage.io\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from efficientnet_pytorch import model as enet\n","\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm_notebook as tqdm\n","\n","import random\n","import os"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                           image_id data_provider\n","0  005700be7e06878e6605e7a5a39de1b2       radboud\n","1  005c6e8877caf724c600fdce5d417d40    karolinska\n","2  0104f76634ff89bfff1ef0804a95c380       radboud\n","E:\\data\\prostate-cancer-grade-assessment\\train_images\n"]}],"source":["data_dir = '/data/prostate-cancer-grade-assessment/'\n","df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","df_test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n","df_sub = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\n","\n","model_dir = './panda-public-models/'\n","\n","image_folder = os.path.join(data_dir, 'test_images')\n","is_test = os.path.exists(image_folder)  # IF test_images is not exists, we will use some train images.\n","image_folder = image_folder if is_test else os.path.join(data_dir, 'train_images')\n","\n","image_folder = r'E:\\data\\prostate-cancer-grade-assessment\\train_images'\n","\n","desiredNumberOfImages = int(10)    #Due to processing and time requirements insert in the parenthesis the number of images which are desired to be analysed\n","seedValue = 315019\n","\n","def generate_random_subdataset(df, num_images, seed):     \n","    random.seed(seed)\n","    return df.sample(n=num_images, random_state=random.randint(0, 1000))\n","\n","subDf_train = generate_random_subdataset(df_train, desiredNumberOfImages, seedValue)\n","df = df_test if is_test else subDf_train\n","\n","print(df)\n","\n","tile_size = 256\n","image_size = 256\n","n_tiles = 36\n","batch_size = 8\n","num_workers = 4\n","\n","device = torch.device('cuda')\n","print(image_folder)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["./panda-public-models/cls_effnet_b0_Rand36r36tiles256_big_bce_lr0.3_augx2_30epo_model_fold0.pth loaded!\n","./pandaenetb042x256x256x3/enet_b1_8ep_fold0.pth loaded!\n"]}],"source":["class enetv2(nn.Module):\n","    def __init__(self, backbone, out_dim):\n","        super(enetv2, self).__init__()\n","        self.enet = enet.EfficientNet.from_name(backbone)  # Initialize the EfficientNet backbone\n","        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)  # Add a fully connected layer for final classification\n","        self.enet._fc = nn.Identity()  # Replace the original fully connected layer with an identity layer\n","\n","    def extract(self, x):\n","        return self.enet(x)  # Extract features using the EfficientNet backbone\n","\n","    def forward(self, x):\n","        x = self.extract(x)  # Extract features\n","        x = self.myfc(x)  # Perform final classification\n","        return x\n","\n","\n","def load_models(model_files):\n","    models = []\n","    for model_f in model_files:\n","        model_f = os.path.join(model_dir, model_f)                 # Get the file path of the model\n","        backbone = 'efficientnet-b0'\n","        model = enetv2(backbone, out_dim=5)                       # Create an instance of the enetv2 model\n","        model.load_state_dict(torch.load(model_f, map_location=lambda storage, loc: storage), strict=True)  # Load the model weights\n","        model.eval()  # Set the model to evaluation mode\n","        model.to(device)                                         # Move the model to the specified device (e.g., GPU)\n","        models.append(model)                                    # Add the model to the list of models\n","        print(f'{model_f} loaded!')\n","    return models\n","\n","\n","model_files = [\n","    'cls_effnet_b0_Rand36r36tiles256_big_bce_lr0.3_augx2_30epo_model_fold0.pth'\n","]\n","\n","models = load_models(model_files)  # Load the models\n","\n","\n","model_dir2 = './pandaenetb042x256x256x3/'\n","def load_models2(model_files):\n","    models = []\n","    for model_f in model_files:\n","        model_f = os.path.join(model_dir2, model_f)  # Get the file path of the model\n","        backbone = 'efficientnet-b1'\n","        model = enetv2(backbone, out_dim=5)                              # Create an instance of the enetv2 model\n","        model.load_state_dict(torch.load(model_f, map_location=lambda storage, loc: storage), strict=True)  # Load the model weights\n","        model.eval()                           # Set the model to evaluation mode\n","        model.to(device)                       # Move the model to the specified device (e.g., GPU)\n","        models.append(model)                   # Add the model to the list of models\n","        print(f'{model_f} loaded!')\n","    return models\n","\n","\n","model_files2 = [\n","    'enet_b1_8ep_fold0.pth'\n","]\n","\n","models2 = load_models2(model_files2)  # Load the models"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["def get_tiles(img, mode=0):\n","    result = []\n","    \n","    # Get the dimensions of the image\n","    h, w, c = img.shape\n","    \n","    # Calculate padding sizes based on the tile size and mode\n","    pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) // 2)\n","    pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) // 2)\n","    \n","    # Pad the image with white pixels\n","    img2 = np.pad(img, [[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2, pad_w - pad_w // 2], [0, 0]], constant_values=255)\n","    \n","    # Reshape the image into tiles\n","    img3 = img2.reshape(img2.shape[0] // tile_size, tile_size, img2.shape[1] // tile_size, tile_size, 3)\n","    img3 = img3.transpose(0, 2, 1, 3, 4).reshape(-1, tile_size, tile_size, 3)\n","    \n","    # Calculate the number of tiles with non-white pixels\n","    n_tiles_with_info = (img3.reshape(img3.shape[0], -1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n","    \n","    # Pad the image if the number of tiles is less than the desired number\n","    if len(img) < n_tiles:\n","        img3 = np.pad(img3, [[0, n_tiles - len(img3)], [0, 0], [0, 0], [0, 0]], constant_values=255)\n","    \n","    # Sort the tiles based on the sum of pixel values\n","    idxs = np.argsort(img3.reshape(img3.shape[0], -1).sum(-1))[:n_tiles]\n","    img3 = img3[idxs]\n","    \n","    # Create a list of tile images with their corresponding index\n","    for i in range(len(img3)):\n","        result.append({'img': img3[i], 'idx': i})\n","    \n","    return result, n_tiles_with_info >= n_tiles\n","\n","\n","class PANDADataset(Dataset):\n","    def __init__(self,\n","                 df,\n","                 image_size,\n","                 n_tiles=n_tiles,\n","                 tile_mode=0,\n","                 rand=False,\n","                 sub_imgs=False,\n","                 transform=None\n","                ):\n","        self.df = df.reset_index(drop=True)\n","        self.image_size = image_size\n","        self.n_tiles = n_tiles\n","        self.tile_mode = tile_mode\n","        self.rand = rand\n","        self.sub_imgs = sub_imgs\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return self.df.shape[0]\n","\n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        img_id = row.image_id\n","        \n","        tiff_file = os.path.join(image_folder, f'{img_id}.tiff')\n","        image = skimage.io.MultiImage(tiff_file)[1]\n","        \n","        tiles, OK = get_tiles(image, self.tile_mode)  # Get the tiles using the get_tiles function\n","        \n","        # Generate random indexes for selecting tiles\n","        if self.rand:\n","            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n","        else:\n","            idxes = list(range(self.n_tiles))\n","        \n","        idxes = np.asarray(idxes) + self.n_tiles if self.sub_imgs else idxes               # Adjust the indexes if sub_imgs is True\n","        \n","        n_row_tiles = int(np.sqrt(self.n_tiles))\n","        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n","        \n","        # Construct the image from selected tiles\n","        for h in range(n_row_tiles):\n","            for w in range(n_row_tiles):\n","                i = h * n_row_tiles + w\n","    \n","                if len(tiles) > idxes[i]:\n","                    this_img = tiles[idxes[i]]['img']\n","                else:\n","                    this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n","                this_img = 255 - this_img\n","                h1 = h * image_size\n","                w1 = w * image_size\n","                images[h1:h1+image_size, w1:w1+image_size] = this_img\n","        \n","        if self.transform is not None:                # Apply transformations to the image\n","            images = self.transform(image=images)['image']\n","            \n","        # Convert image to float32 and normalize\n","        images = images.astype(np.float32)\n","        images /= 255\n","        \n","        # Transpose image to match PyTorch format\n","        images = images.transpose(2, 0, 1)\n","        \n","        return torch.tensor(images)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["if not is_test:             # Create a dataset for visualization\n","    dataset_show = PANDADataset(df, image_size, n_tiles, 0)\n","    # Set the figure size for plotting\n","    from pylab import rcParams\n","    rcParams['figure.figsize'] = 20, 10\n","    \n","    # Generate subplots for visualization\n","    for i in range(2):\n","        f, axarr = plt.subplots(1, 5)\n","        \n","        # Select random images from the dataset\n","        for p in range(5):\n","            idx = np.random.randint(0, len(dataset_show))\n","            img = dataset_show[idx]\n","            axarr[p].imshow(1. - img.transpose(0, 1).transpose(1, 2).squeeze())\n","            axarr[p].set_title(str(idx))"]},{"cell_type":"markdown","metadata":{},"source":["# Prediction"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["import albumentations\n","\n","# Define training transformations\n","transforms_train = albumentations.Compose([\n","    albumentations.Transpose(p=0.5),\n","    albumentations.VerticalFlip(p=0.5),\n","    albumentations.HorizontalFlip(p=0.5),\n","])\n","\n","# Define validation transformations (empty)\n","transforms_val = albumentations.Compose([])\n","\n","# Define additional validation transformations\n","transforms_val1 = albumentations.Compose([\n","    albumentations.Transpose(p=1)\n","])\n","\n","transforms_val2 = albumentations.Compose([\n","    albumentations.VerticalFlip(p=1)\n","])\n","\n","transforms_val3= albumentations.Compose([\n","    albumentations.HorizontalFlip(p=1),\n","])\n","\n","transforms_val4= albumentations.Compose([\n","    albumentations.Transpose(p=1),\n","    albumentations.VerticalFlip(p=1),\n","    albumentations.HorizontalFlip(p=1),\n","])"]},{"cell_type":"markdown","metadata":{},"source":["# Model Inference"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\chwo6\\AppData\\Local\\Temp\\ipykernel_11052\\1249650881.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for data in tqdm(loader):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"012bac178fe54e578190591480473bf3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"RuntimeError","evalue":"DataLoader worker (pid(s) 4060, 1124, 13452, 4800) exited unexpectedly","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\chwo6\\AppData\\Local\\anaconda3\\envs\\xray2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1133\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n","File \u001b[1;32mc:\\Users\\chwo6\\AppData\\Local\\anaconda3\\envs\\xray2\\lib\\multiprocessing\\queues.py:108\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n","\u001b[1;31mEmpty\u001b[0m: ","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32me:\\input\\pro\\prostate-cancer-and-grade-assessment-group-f.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/input/pro/prostate-cancer-and-grade-assessment-group-f.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Perform inference without gradient computation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/input/pro/prostate-cancer-and-grade-assessment-group-f.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/input/pro/prostate-cancer-and-grade-assessment-group-f.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/input/pro/prostate-cancer-and-grade-assessment-group-f.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)  \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/input/pro/prostate-cancer-and-grade-assessment-group-f.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         logits \u001b[39m=\u001b[39m models[\u001b[39m0\u001b[39m](data)  \n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[1;32m--> 249\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[0;32m    250\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    251\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m    252\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\chwo6\\AppData\\Local\\anaconda3\\envs\\xray2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[1;32mc:\\Users\\chwo6\\AppData\\Local\\anaconda3\\envs\\xray2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\chwo6\\AppData\\Local\\anaconda3\\envs\\xray2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n","File \u001b[1;32mc:\\Users\\chwo6\\AppData\\Local\\anaconda3\\envs\\xray2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(failed_workers) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1144\u001b[0m     pids_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(w\u001b[39m.\u001b[39mpid) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1145\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataLoader worker (pid(s) \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exited unexpectedly\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(pids_str)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, queue\u001b[39m.\u001b[39mEmpty):\n\u001b[0;32m   1147\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n","\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 4060, 1124, 13452, 4800) exited unexpectedly"]}],"source":["# Create PANDADataset with mode 0\n","dataset = PANDADataset(df, image_size, n_tiles, 0, False, False, transforms_val)\n","# Create DataLoader for dataset with specified batch size, num_workers, and shuffle=False\n","loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","\n","# Create another PANDADataset with mode 2\n","dataset2 = PANDADataset(df, image_size, n_tiles, 2, False, False, transforms_val)\n","# Create DataLoader for dataset2 with specified batch size, num_workers, and shuffle=False\n","loader2 = DataLoader(dataset2, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","\n","# Initialize empty lists to store logits\n","LOGITS = []\n","LOGITS2 = []\n","LOGITS3 = []\n","LOGITS4 = []\n","\n","# Perform inference without gradient computation\n","with torch.no_grad():\n","    for data in tqdm(loader):\n","        data = data.to(device)  \n","        logits = models[0](data)  \n","        LOGITS.append(logits) \n","        logits = models2[0](data)  \n","        LOGITS3.append(logits)  \n","\n","    for data in tqdm(loader2):\n","        data = data.to(device)  \n","        logits = models[0](data)  \n","        LOGITS2.append(logits)  \n","        logits = models2[0](data)  \n","        LOGITS4.append(logits) \n","\n","# Concatenate and process the logits to obtain predictions\n","LOGITS = (\n","    torch.cat(LOGITS).sigmoid().cpu() +\n","    torch.cat(LOGITS2).sigmoid().cpu() +\n","    torch.cat(LOGITS3).sigmoid().cpu() +\n","    torch.cat(LOGITS4).sigmoid().cpu()\n",") / 4\n","# Sum along the 1st dimension of the logits and convert to NumPy array\n","PREDS = LOGITS.sum(1).numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","dataset = PANDADataset(df, image_size, n_tiles, 0, False, False, transforms_val1 )  # mode == 0\n","loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","\n","dataset2 = PANDADataset(df, image_size, n_tiles, 2, False, False, transforms_val1 )  # mode == 2\n","loader2 = DataLoader(dataset2, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","\n","\n","LOGITS = []\n","LOGITS2 = []\n","LOGITS3 = []\n","LOGITS4 = []\n","with torch.no_grad():\n","    for data in tqdm(loader):\n","        data = data.to(device)\n","        logits = models[0](data)\n","        LOGITS.append(logits)\n","        logits = models2[0](data)\n","        LOGITS3.append(logits)\n","        \n","    for data in tqdm(loader2):\n","        data = data.to(device)\n","        logits = models[0](data)\n","        LOGITS2.append(logits)\n","        logits = models2[0](data)\n","        LOGITS4.append(logits)\n","        \n","LOGITS = (torch.cat(LOGITS).sigmoid().cpu()+torch.cat(LOGITS2).sigmoid().cpu()+torch.cat(LOGITS3).sigmoid().cpu()+torch.cat(LOGITS4).sigmoid().cpu()) / 4\n","PREDS1 = LOGITS.sum(1).numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = PANDADataset(df, image_size, n_tiles, 0, False, False, transforms_val2 )  # mode == 0\n","loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","\n","dataset2 = PANDADataset(df, image_size, n_tiles, 2, False, False, transforms_val2 )  # mode == 2\n","loader2 = DataLoader(dataset2, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","\n","\n","LOGITS = []\n","LOGITS2 = []\n","LOGITS3 = []\n","LOGITS4 = []\n","with torch.no_grad():\n","    for data in tqdm(loader):\n","        data = data.to(device)\n","        logits = models[0](data)\n","        LOGITS.append(logits)\n","        logits = models2[0](data)\n","        LOGITS3.append(logits)\n","        \n","    for data in tqdm(loader2):\n","        data = data.to(device)\n","        logits = models[0](data)\n","        LOGITS2.append(logits)\n","        logits = models2[0](data)\n","        LOGITS4.append(logits)\n","        \n","LOGITS = (torch.cat(LOGITS).sigmoid().cpu()+torch.cat(LOGITS2).sigmoid().cpu()+torch.cat(LOGITS3).sigmoid().cpu()+torch.cat(LOGITS4).sigmoid().cpu()) / 4\n","PREDS2 = LOGITS.sum(1).numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = PANDADataset(df, image_size, n_tiles, 0, False, False, transforms_val3 )  # mode == 0\n","loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","\n","dataset2 = PANDADataset(df, image_size, n_tiles, 2, False, False, transforms_val3 )  # mode == 2\n","loader2 = DataLoader(dataset2, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","\n","\n","LOGITS = []\n","LOGITS2 = []\n","LOGITS3 = []\n","LOGITS4 = []\n","with torch.no_grad():\n","    for data in tqdm(loader):\n","        data = data.to(device)\n","        logits = models[0](data)\n","        LOGITS.append(logits)\n","        logits = models2[0](data)\n","        LOGITS3.append(logits)\n","        \n","    for data in tqdm(loader2):\n","        data = data.to(device)\n","        logits = models[0](data)\n","        LOGITS2.append(logits)\n","        logits = models2[0](data)\n","        LOGITS4.append(logits)\n","        \n","LOGITS = (torch.cat(LOGITS).sigmoid().cpu()+torch.cat(LOGITS2).sigmoid().cpu()+torch.cat(LOGITS3).sigmoid().cpu()+torch.cat(LOGITS4).sigmoid().cpu()) / 4\n","PREDS3 = LOGITS.sum(1).numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = PANDADataset(df, image_size, n_tiles, 0, False, False, transforms_val4 )  # mode == 0\n","loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","\n","dataset2 = PANDADataset(df, image_size, n_tiles, 2, False, False, transforms_val4 )  # mode == 2\n","loader2 = DataLoader(dataset2, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n","\n","\n","LOGITS = []\n","LOGITS2 = []\n","LOGITS3 = []\n","LOGITS4 = []\n","with torch.no_grad():\n","    for data in tqdm(loader):\n","        data = data.to(device)\n","        logits = models[0](data)\n","        LOGITS.append(logits)\n","        logits = models2[0](data)\n","        LOGITS3.append(logits)\n","        \n","    for data in tqdm(loader2):\n","        data = data.to(device)\n","        logits = models[0](data)\n","        LOGITS2.append(logits)\n","        logits = models2[0](data)\n","        LOGITS4.append(logits)\n","        \n","LOGITS = (torch.cat(LOGITS).sigmoid().cpu()+torch.cat(LOGITS2).sigmoid().cpu()+torch.cat(LOGITS3).sigmoid().cpu()+torch.cat(LOGITS4).sigmoid().cpu()) / 4\n","PREDS4 = LOGITS.sum(1).numpy()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Predictions of the Models"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["# # Install efficientnet package\n","# !pip install ../input/kaggle-efficientnet-repo/efficientnet-1.0.0-py3-none-any.whl\n","\n","# Import necessary libraries\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm\n","import argparse\n","import os\n","import skimage.io\n","from scipy.ndimage import measurements\n","import os\n","import numpy as np\n","import pandas as pd\n","import argparse\n","import tensorflow as tf\n","from keras.optimizers import Adam\n","from keras.losses import categorical_crossentropy\n","from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n","from keras import layers as L\n","import efficientnet.tfkeras as efn\n","from keras.utils import to_categorical\n","import gc\n","import albumentations\n","gc.enable()\n","\n","# Set parameters\n","sz = 256\n","N = 48\n","\n","# Function to generate image patches\n","def tile(img):\n","    result = []\n","    shape = img.shape\n","    pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n","    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],constant_values=255)\n","    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n","    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n","    if len(img) < N:\n","        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n","    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n","    img = img[idxs]\n","    return img\n","\n","# Function to generate larger image patches\n","def tile2(img):\n","    result = []\n","    shape = img.shape\n","    pad0,pad1 = (sz - shape[0]%sz)%sz + ((sz * 2) // 2), (sz - shape[1]%sz)%sz + ((sz * 2) // 2)\n","    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],constant_values=255)\n","    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n","    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n","    if len(img) < N:\n","        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n","    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n","    img = img[idxs]\n","    return img\n","\n","# Define the ConvNet model\n","class ConvNet(tf.keras.Model):\n","    def __init__(self, engine, input_shape, weights):\n","        super(ConvNet, self).__init__()\n","        self.engine = engine(include_top=False, input_shape=input_shape, weights=weights)\n","        self.avg_pool2d = tf.keras.layers.GlobalAveragePooling2D()\n","        self.dropout = tf.keras.layers.Dropout(0.5)\n","        self.dense_1 = tf.keras.layers.Dense(1024)\n","        self.dense_2 = tf.keras.layers.Dense(5, activation='sigmoid')\n","\n","    @tf.function\n","    def call(self, inputs, **kwargs):\n","        x = tf.reshape(inputs, (-1, IMG_SIZE, IMG_SIZE, 3))\n","        x = self.engine(x)\n","        shape = x.shape\n","        x = tf.reshape(x, (-1, N_TILES, shape[1], shape[2], shape[3])) \n","        x = tf.transpose(x, perm=[0, 2, 1, 3, 4])\n","        x = tf.reshape(x, (-1, shape[1], N_TILES * shape[2], shape[3])) \n","        x = self.avg_pool2d(x)\n","        x = self.dropout(x, training=False)\n","        x = self.dense_1(x)\n","        x = tf.nn.relu(x)\n","        return self.dense_2(x)\n","    \n","# Here we set configuration parameters\n","is_ef = True\n","backbone_name = 'efficientnet-b0'\n","N_TILES = 48\n","IMG_SIZE = 256\n","\n","# Check if the backbone name starts with 'efficientnet' and get the corresponding model function\n","if backbone_name.startswith('efficientnet'):\n","    model_fn = getattr(efn, f'EfficientNetB{backbone_name[-1]}')\n","\n","# Initialize the model\n","model = ConvNet(engine=model_fn, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=None)\n","\n","TRAIN = '/data/prostate-cancer-grade-assessment/train_images/'\n","MASKS = '/data/prostate-cancer-grade-assessment/train_label_masks/'\n","BASE_PATH = '/data/prostate-cancer-grade-assessment/'\n","train = pd.read_csv(BASE_PATH + \"train.csv\")\n","sub = pd.read_csv(\"/data/prostate-cancer-grade-assessment/sample_submission.csv\")\n","test = pd.read_csv(\"/data/prostate-cancer-grade-assessment/test.csv\")\n","TEST = '/data/prostate-cancer-grade-assessment/test_images/'\n","PRED_PATH = TEST \n","df = sub\n","t_df = test\n","\n","# Define transformations for validation\n","transforms_val0 = albumentations.Compose([])\n","transforms_val1 = albumentations.Compose([\n","    albumentations.VerticalFlip(p=1)\n","])\n","transforms_val2 = albumentations.Compose([\n","    albumentations.HorizontalFlip(p=0.5),\n","    albumentations.VerticalFlip(p=0.5)\n","])\n","transforms_val3 = albumentations.Compose([\n","    albumentations.HorizontalFlip(p=0.5),\n","    albumentations.VerticalFlip(p=0.5)\n","])\n","\n","# Set the number of Test Time Augmentations (TTA) iterations and create dummy data in order to allow for model initialization\n","n_TTA = 2        \n","dummy_data = tf.zeros((n_TTA * N_TILES, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)\n","_ = model(dummy_data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\n","model.load_weights('/')\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions10 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.5*np.sum(pred)\n","        predictions10.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions10 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.5*np.sum(pred)\n","        predictions10.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions12 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.5*np.sum(pred)\n","        predictions12.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df = subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions12 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.5*np.sum(pred)\n","        predictions12.append(isup)\n","\n","        del patches, img\n","        gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","class ConvNet(tf.keras.Model):\n","\n","    def __init__(self, engine, input_shape, weights):\n","        super(ConvNet, self).__init__()\n","        \n","        self.engine = engine(\n","            include_top=False, input_shape=input_shape, weights=weights)\n","        \n","        \n","        self.avg_pool2d = tf.keras.layers.GlobalAveragePooling2D()\n","        self.dropout = tf.keras.layers.Dropout(0.5)\n","        self.dense_1 = tf.keras.layers.Dense(1024)\n","        self.dense_2 = tf.keras.layers.Dense(5,activation='sigmoid')\n","\n","    @tf.function\n","    def call(self, inputs, **kwargs):\n","        x = tf.reshape(inputs, (-1, IMG_SIZE, IMG_SIZE, 3))\n","        x = self.engine(x)\n","        shape = x.shape\n","        x = tf.reshape(x, (-1, N_TILES, shape[1], shape[2], shape[3])) \n","        x = tf.transpose(x, perm=[0, 2, 1, 3, 4])\n","        x = tf.reshape(x, (-1, shape[1], N_TILES*shape[2], shape[3])) \n","        x = self.avg_pool2d(x)\n","        x = self.dropout(x, training=False)\n","        x = self.dense_1(x)\n","        x = tf.nn.relu(x)\n","        return self.dense_2(x)\n","    \n","is_ef = True\n","backbone_name = 'efficientnet-b1'\n","N_TILES = 48\n","IMG_SIZE = 256\n","\n","\n","if backbone_name.startswith('efficientnet'):\n","    model_fn = getattr(efn, f'EfficientNetB{backbone_name[-1]}')\n","    \n","model = ConvNet(engine=model_fn, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=None)\n","\n","\n","\n","\n","n_TTA = 2        \n","dummy_data = tf.zeros((n_TTA * N_TILES, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)\n","_ = model(dummy_data)        \n","\n","\n","TRAIN = '../input/prostate-cancer-grade-assessment/train_images/'\n","MASKS = '../input/prostate-cancer-grade-assessment/train_label_masks/'\n","BASE_PATH = '../input/prostate-cancer-grade-assessment/'\n","train = pd.read_csv(BASE_PATH + \"train.csv\")\n","train.head()\n","\n","sub = pd.read_csv(\"../input/prostate-cancer-grade-assessment/sample_submission.csv\")\n","sub.head()\n","\n","test = pd.read_csv(\"../input/prostate-cancer-grade-assessment/test.csv\")\n","test.head()\n","\n","TEST = '../input/prostate-cancer-grade-assessment/test_images/'\n","\n","\n","PRED_PATH = TEST \n","df = sub\n","t_df = test"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\n","model.load_weights('../input/pandaenetb042x256x256x3/efficientnet-b1-48-full-epochs60.h5')\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions20 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.5*np.sum(pred)\n","        predictions20.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions20 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.5*np.sum(pred)\n","        predictions20.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions22 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.5*np.sum(pred)\n","        predictions22.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions22 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.5*np.sum(pred)\n","        predictions22.append(isup)\n","\n","        del patches, img\n","        gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","class ConvNet(tf.keras.Model):\n","\n","    def __init__(self, engine, input_shape, weights):\n","        super(ConvNet, self).__init__()\n","        \n","        self.engine = engine(\n","            include_top=False, input_shape=input_shape, weights=weights)\n","        \n","        \n","        self.avg_pool2d = tf.keras.layers.GlobalAveragePooling2D()\n","        self.dropout = tf.keras.layers.Dropout(0.5)\n","        self.dense_1 = tf.keras.layers.Dense(1024)\n","        self.dense_2 = tf.keras.layers.Dense(5,activation='sigmoid')\n","\n","    @tf.function\n","    def call(self, inputs, **kwargs):\n","        x = tf.reshape(inputs, (-1, IMG_SIZE, IMG_SIZE, 3))\n","        x = self.engine(x)\n","        shape = x.shape\n","        x = tf.reshape(x, (-1, N_TILES, shape[1], shape[2], shape[3])) \n","        x = tf.transpose(x, perm=[0, 2, 1, 3, 4])\n","        x = tf.reshape(x, (-1, shape[1], N_TILES*shape[2], shape[3])) \n","        x = self.avg_pool2d(x)\n","        x = self.dropout(x, training=False)\n","        x = self.dense_1(x)\n","        x = tf.nn.relu(x)\n","        return self.dense_2(x)\n","    \n","is_ef = True\n","backbone_name = 'efficientnet-b2'\n","N_TILES = 48\n","IMG_SIZE = 256\n","\n","\n","if backbone_name.startswith('efficientnet'):\n","    model_fn = getattr(efn, f'EfficientNetB{backbone_name[-1]}')\n","    \n","model = ConvNet(engine=model_fn, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=None)\n","\n","\n","n_TTA = 2        \n","dummy_data = tf.zeros((n_TTA * N_TILES, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)\n","_ = model(dummy_data)           \n","\n","\n","\n","TRAIN = '../input/prostate-cancer-grade-assessment/train_images/'\n","MASKS = '../input/prostate-cancer-grade-assessment/train_label_masks/'\n","BASE_PATH = '../input/prostate-cancer-grade-assessment/'\n","train = pd.read_csv(BASE_PATH + \"train.csv\")\n","train.head()\n","\n","sub = pd.read_csv(\"../input/prostate-cancer-grade-assessment/sample_submission.csv\")\n","sub.head()\n","\n","test = pd.read_csv(\"../input/prostate-cancer-grade-assessment/test.csv\")\n","test.head()\n","\n","TEST = '../input/prostate-cancer-grade-assessment/test_images/'\n","\n","\n","PRED_PATH = TEST \n","df = sub\n","t_df = test"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\n","model.load_weights('../input/pandaenetb042x256x256x3/efficientnet-b2-48-full-epochs60.h5')\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions30 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.5*np.sum(pred)\n","        predictions30.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions30 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.5*np.sum(pred)\n","        predictions30.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions32 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.5*np.sum(pred)\n","        predictions32.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions32 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.5*np.sum(pred)\n","        predictions32.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","        \n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","from tensorflow.keras.applications import densenet as den\n","\n","class ConvNet(tf.keras.Model):\n","\n","    def __init__(self, engine, input_shape, weights):\n","        super(ConvNet, self).__init__()\n","        \n","        self.engine = engine(\n","            include_top=False, input_shape=input_shape, weights=weights)\n","        \n","        \n","        self.avg_pool2d = tf.keras.layers.GlobalAveragePooling2D()\n","        self.dropout = tf.keras.layers.Dropout(0.5)\n","        self.dense_1 = tf.keras.layers.Dense(1024)\n","        self.dense_2 = tf.keras.layers.Dense(5,activation='sigmoid')\n","\n","    @tf.function\n","    def call(self, inputs, **kwargs):\n","        x = tf.reshape(inputs, (-1, IMG_SIZE, IMG_SIZE, 3))\n","        x = self.engine(x)\n","        shape = x.shape\n","        x = tf.reshape(x, (-1, N_TILES, shape[1], shape[2], shape[3])) \n","        x = tf.transpose(x, perm=[0, 2, 1, 3, 4])\n","        x = tf.reshape(x, (-1, shape[1], N_TILES*shape[2], shape[3])) \n","        x = self.avg_pool2d(x)\n","        x = self.dropout(x, training=False)\n","        x = self.dense_1(x)\n","        x = tf.nn.relu(x)\n","        return self.dense_2(x)\n","    \n","\n","\n","N_TILES = 48\n","IMG_SIZE = 256\n","\n","\n","\n","model_fn = getattr(den, 'DenseNet121')\n","    \n","model = ConvNet(engine=model_fn, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=None)\n","\n","\n","n_TTA = 4        \n","dummy_data = tf.zeros((n_TTA * N_TILES, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)\n","_ = model(dummy_data)      \n","\n","\n","\n","TRAIN = '/data/prostate-cancer-grade-assessment/train_images/'\n","MASKS = '/data/prostate-cancer-grade-assessment/train_images/train_label_masks/'\n","BASE_PATH = '/data/prostate-cancer-grade-assessment/train_images/'\n","train = pd.read_csv(BASE_PATH + \"train.csv\")\n","train.head()\n","\n","sub = pd.read_csv(\"/data/prostate-cancer-grade-assessment/sample_submission.csv\")\n","sub.head()\n","\n","test = pd.read_csv(\"/data/prostate-cancer-grade-assessment/test.csv\")\n","test.head()\n","\n","TEST = '/data/prostate-cancer-grade-assessment/test_images/'\n","\n","\n","PRED_PATH = TEST \n","df = sub\n","t_df = test"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\n","model.load_weights('../input/pandaenetb042x256x256x3/DenseNet121-48-full-epochs60.h5')\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions40 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","        patches1 = patches.copy()\n","        patches2 = patches.copy()\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches1[k, ] = transforms_val0(image=patches1[k, ])['image']\n","            patches2[k, ] = transforms_val1(image=patches2[k, ])['image']\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches1, patches2, patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.25*np.sum(pred)\n","        predictions40.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions40 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","        patches1 = patches.copy()\n","        patches2 = patches.copy()\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches1[k, ] = transforms_val0(image=patches1[k, ])['image']\n","            patches2[k, ] = transforms_val1(image=patches2[k, ])['image']\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches1, patches2, patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.25*np.sum(pred)\n","        predictions40.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions42 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","        patches1 = patches.copy()\n","        patches2 = patches.copy()\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches1[k, ] = transforms_val0(image=patches1[k, ])['image']\n","            patches2[k, ] = transforms_val1(image=patches2[k, ])['image']\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches1, patches2, patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.25*np.sum(pred)\n","        predictions42.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions42 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","        patches1 = patches.copy()\n","        patches2 = patches.copy()\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches1[k, ] = transforms_val0(image=patches1[k, ])['image']\n","            patches2[k, ] = transforms_val1(image=patches2[k, ])['image']\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches1, patches2, patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image) \n","        isup = 0.25*np.sum(pred)\n","        predictions42.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","\n","        \n","del model, dummy_data, sub, pred, train, isup, image\n","del patches1,patches2,patches3,patches4    \n","\n","gc.collect()  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","sz = 256\n","N = 42\n","def tile(img):\n","    result = []\n","    shape = img.shape\n","    pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n","    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],constant_values=255)\n","    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n","    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n","    if len(img) < N:\n","        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n","    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n","    img = img[idxs]\n","    return img\n","\n","def tile2(img):\n","    result = []\n","    shape = img.shape\n","    pad0,pad1 = (sz - shape[0]%sz)%sz + ((sz * 2) // 2), (sz - shape[1]%sz)%sz + ((sz * 2) // 2)\n","    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],constant_values=255)\n","    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n","    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n","    if len(img) < N:\n","        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n","    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n","    img = img[idxs]\n","    return img\n","\n","\n","\n","\n","class ConvNet(tf.keras.Model):\n","\n","    def __init__(self, engine, input_shape, weights):\n","        super(ConvNet, self).__init__()\n","        \n","        self.engine = engine(\n","            include_top=False, input_shape=input_shape, weights=weights)\n","        \n","        \n","        self.avg_pool2d = tf.keras.layers.GlobalAveragePooling2D()\n","        self.dropout = tf.keras.layers.Dropout(0.5)\n","        self.dense_1 = tf.keras.layers.Dense(1024)\n","        self.dense_2 = tf.keras.layers.Dense(1)\n","\n","    @tf.function\n","    def call(self, inputs, **kwargs):\n","        x = tf.reshape(inputs, (-1, IMG_SIZE, IMG_SIZE, 3))\n","        x = self.engine(x)\n","        shape = x.shape\n","        x = tf.reshape(x, (-1, N_TILES, shape[1], shape[2], shape[3])) \n","        x = tf.transpose(x, perm=[0, 2, 1, 3, 4])\n","        x = tf.reshape(x, (-1, shape[1], N_TILES*shape[2], shape[3])) \n","        x = self.avg_pool2d(x)\n","        x = self.dropout(x, training=False)\n","        x = self.dense_1(x)\n","        x = tf.nn.relu(x)\n","        return self.dense_2(x)\n","    \n","is_ef = True\n","backbone_name = 'efficientnet-b0'\n","\n","N_TILES = 42\n","IMG_SIZE = 256\n","\n","if backbone_name.startswith('efficientnet'):\n","    model_fn = getattr(efn, f'EfficientNetB{backbone_name[-1]}')\n","\n","    \n","model = ConvNet(engine=model_fn, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=None)\n","\n","\n","\n","TRAIN = '../input/prostate-cancer-grade-assessment/train_images/'\n","MASKS = '../input/prostate-cancer-grade-assessment/train_label_masks/'\n","BASE_PATH = '../input/prostate-cancer-grade-assessment/'\n","train = pd.read_csv(BASE_PATH + \"train.csv\")\n","train.head()\n","\n","sub = pd.read_csv(\"../input/prostate-cancer-grade-assessment/sample_submission.csv\")\n","sub.head()\n","\n","test = pd.read_csv(\"../input/prostate-cancer-grade-assessment/test.csv\")\n","test.head()\n","\n","TEST = '../input/prostate-cancer-grade-assessment/test_images/'\n","\n","\n","PRED_PATH = TEST \n","df = sub\n","t_df = test\n","\n","\n","\n","\n","####\n","\n","\n","\n","\n","\n","n_TTA = 2        \n","dummy_data = tf.zeros((n_TTA * N_TILES, IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)\n","_ = model(dummy_data)   \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\n","model.load_weights('../input/pandaenetb042x256x256x3/efficientnet-b0-fold0-epochs40.h5')\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions50 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image)\n","        isup = np.mean(pred)\n","        predictions50.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions50 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image)\n","        isup = np.mean(pred)\n","        predictions50.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions52 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image)\n","        isup = np.mean(pred)\n","        predictions52.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions52 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image)\n","        isup = np.mean(pred)\n","        predictions52.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","        \n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\n","model.load_weights('../input/pandaenetb042x256x256x3/efficientnet-b0-fold4-epochs60.h5')\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions60 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image)\n","        isup = np.mean(pred)\n","        predictions60.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions60 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image)\n","        isup = np.mean(pred)\n","        predictions60.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions62 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image)\n","        isup = np.mean(pred)\n","        predictions62.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions62 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image)\n","        isup = np.mean(pred)\n","        predictions62.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","        \n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(lr= 1e-05), loss= tf.nn.sigmoid_cross_entropy_with_logits)\n","model.load_weights('../input/pandaenetb042x256x256x3/efficientnet-b0-fold2-epochs40.h5')\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions70 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image)\n","        isup = np.mean(pred)\n","        predictions70.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions70 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image)\n","        isup = np.mean(pred)\n","        predictions70.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","\n","####\n","\n","if os.path.exists(PRED_PATH):\n","    predictions72 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image)\n","        isup = np.mean(pred)\n","        predictions72.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","\n","else:\n","    PRED_PATH = TRAIN\n","    df_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n","    df=subDf_train\n","    df = df[['image_id','isup_grade']].copy()\n","    predictions72 = []\n","    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n","        \n","        \n","        image_id = row['image_id']\n","        \n","        img_path = PRED_PATH + image_id + '.tiff' #BASE_PATH\n","        \n","        img = skimage.io.MultiImage(img_path)[1]\n","        \n","        patches = tile2(img)\n","\n","        patches3 = patches.copy()\n","        patches4 = patches.copy() \n","        \n","        k = 0\n","        while k < N_TILES:\n","            patches3[k, ] = transforms_val2(image=patches3[k, ])['image']\n","            patches4[k, ] = transforms_val3(image=patches4[k, ])['image']\n","            k += 1\n","        \n","        image = np.stack([patches3, patches4])\n","        image = image / 255.0\n","        \n","        pred = model.predict(image)\n","        isup = np.mean(pred)\n","        predictions72.append(isup)\n","\n","        del patches, img\n","        gc.collect()\n","        \n","\n","\n","\n","del model, dummy_data, sub, pred, train, isup, image\n","del patches3,patches4    \n","\n","gc.collect()  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Calculate the weighted average of predictions\n","PREDS = (1/5)*PREDS + (1/5)*PREDS1 + (1/5)*PREDS2 + (1/5)*PREDS3 + (1/5)*PREDS4\n","\n","# Calculate the final predictions using a weighted average. The weights were determined looking at other \n","# solutions present in the literature\n","FINAL = np.round((6/10)*PREDS +\n","                  (2/60)*np.array(predictions10) + (2/60)*np.array(predictions12) + \n","                  (2/60)*np.array(predictions20) + (2/60)*np.array(predictions22) +\n","                  (2/60)*np.array(predictions30) + (2/60)*np.array(predictions32) +\n","                  (0.5/10)*np.array(predictions40) + (0.5/10)*np.array(predictions42) +\n","                  (1/60)*np.array(predictions50) + (1/60)*np.array(predictions52) +\n","                  (1/60)*np.array(predictions60) + (1/60)*np.array(predictions62) +\n","                  (1/60)*np.array(predictions70) + (1/60)*np.array(predictions72))\n","\n","# Convert the final predictions to integer values\n","df['isup_grade'] = FINAL.astype(int)\n","\n","# Save the predictions to a CSV file\n","df[['image_id', 'isup_grade']].to_csv('submission.csv', index=False)\n","\n","# Calculate and print some statistics\n","true_values = np.array(subDf_train['isup_grade'])\n","print(df.head())\n","print()\n","print(df.isup_grade.value_counts())"]},{"cell_type":"markdown","metadata":{},"source":["# Results and Model Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Calculate the average predictions for each model\n","average_predictions1 = np.round(np.mean([predictions10, predictions12], axis=0))\n","average_predictions2 = np.round(np.mean([predictions20, predictions22], axis=0))\n","average_predictions3 = np.round(np.mean([predictions30, predictions32], axis=0))\n","average_predictions4 = np.round(np.mean([predictions40, predictions42], axis=0))\n","average_predictions5 = np.round(np.mean([predictions50, predictions52], axis=0))\n","average_predictions6 = np.round(np.mean([predictions60, predictions62], axis=0))\n","average_predictions7 = np.round(np.mean([predictions70, predictions72], axis=0))\n","\n","# Plot the line plot for each set of average predictions\n","plt.plot(average_predictions1, label='efficientnet-b0-48-full-epochs60.h5', marker='o')\n","plt.plot(average_predictions2, label='efficientnet-b1-48-full-epochs60.h5', marker='o')\n","plt.plot(average_predictions3, label='efficientnet-b2-48-full-epochs60.h5', marker='o')\n","plt.plot(average_predictions4, label='DenseNet121-48-full-epochs60.h5', marker='o')\n","plt.plot(average_predictions5, label='efficientnet-b0-fold0-epochs40.h5', marker='o')\n","plt.plot(average_predictions6, label='efficientnet-b0-fold4-epochs60.h5', marker='o')\n","plt.plot(average_predictions7, label='efficientnet-b0-fold2-epochs40.h5', marker='o')\n","\n","# Set the x-axis label\n","plt.xlabel('Image ID')\n","# Set the y-axis label\n","plt.ylabel('Average Predictions')\n","# Set the title of the plot\n","plt.title('Average Predictions for Each Image')\n","# Add a legend to the plot\n","plt.legend()\n","\n","# Rotate the x-axis tick labels vertically\n","plt.xticks(rotation='vertical')\n","\n","# Display the plot\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot the line plot for each set of predictions and true values\n","plt.plot(np.round(PREDS), label='PREDS', marker='o')\n","plt.plot(np.round(PREDS1), label='PREDS1', marker='o')\n","plt.plot(np.round(PREDS2), label='PREDS2', marker='o')\n","plt.plot(np.round(PREDS3), label='PREDS3', marker='o')\n","plt.plot(np.round(PREDS4), label='PREDS4', marker='o')\n","plt.plot(np.round(predictions10), label='efficientnet-b0-48-full-epochs60.h5(1)', marker='o')\n","plt.plot(np.round(predictions12), label='efficientnet-b1-48-full-epochs60.h5(2)', marker='o')\n","plt.plot(np.round(predictions20), label='efficientnet-b2-48-full-epochs60.h5(1)', marker='o')\n","plt.plot(np.round(predictions22), label='efficientnet-b2-48-full-epochs60.h5(2)', marker='o')\n","plt.plot(np.round(predictions30), label='efficientnet-b2-48-full-epochs60.h5(1)', marker='o')\n","plt.plot(np.round(predictions32), label='efficientnet-b2-48-full-epochs60.h5(2)', marker='o')\n","plt.plot(np.round(predictions40), label='DenseNet121-48-full-epochs60.h5(1)', marker='o')\n","plt.plot(np.round(predictions42), label='DenseNet121-48-full-epochs60.h5(2)', marker='o')\n","plt.plot(np.round(predictions50), label='efficientnet-b0-fold0-epochs40.h5(1)', marker='o')\n","plt.plot(np.round(predictions52), label='efficientnet-b0-fold2-epochs40.h5(2)', marker='o')\n","plt.plot(np.round(predictions60), label='efficientnet-b0-fold4-epochs60.h5(1)', marker='o')\n","plt.plot(np.round(predictions62), label='efficientnet-b0-fold4-epochs60.h5(2)', marker='o')\n","plt.plot(np.round(predictions70), label='efficientnet-b0-fold2-epochs40.h5(1)', marker='o')\n","plt.plot(np.round(predictions72), label='efficientnet-b0-fold2-epochs40.h5(2)', marker='o')\n","plt.plot(true_values, marker='o', label='True Value', linewidth=3, linestyle='--')\n","\n","# Set the x-axis label\n","plt.xlabel('Image')\n","# Set the y-axis label\n","plt.ylabel('Average Predictions')\n","# Set the title of the plot\n","plt.title('Average Predictions for Each Image')\n","# Add a legend to the plot\n","plt.legend()\n","plt.xticks(rotation='vertical')\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define the x-axis values (image IDs)\n","image_ids = subDf_train['image_id']\n","\n","# Define the predictions for each model\n","predictions = [\n","    np.round(PREDS),\n","    np.round(PREDS1),\n","    np.round(PREDS2),\n","    np.round(PREDS3),\n","    np.round(PREDS4),\n","    np.round(predictions10),\n","    np.round(predictions12),\n","    np.round(predictions20),\n","    np.round(predictions22),\n","    np.round(predictions30),\n","    np.round(predictions32),\n","    np.round(predictions40),\n","    np.round(predictions42),\n","    np.round(predictions50),\n","    np.round(predictions52),\n","    np.round(predictions60),\n","    np.round(predictions62),\n","    np.round(predictions70),\n","    np.round(predictions72)\n","]\n","prediction_names = [\n","    'PREDS', 'PREDS1', 'PREDS2', 'PREDS3', 'PREDS4', 'predictions10', 'predictions12', 'predictions20', 'predictions22',\n","    'predictions30', 'predictions32', 'predictions40', 'predictions42', 'predictions50', 'predictions52',\n","    'predictions60', 'predictions62', 'predictions70', 'predictions72'\n","]\n","\n","# Define the number of rows and columns for subplots\n","num_rows = 4\n","num_cols = 5\n","\n","# Create subplots for comparing each model's predictions with the true values\n","fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 16))\n","\n","# Iterate through each model's predictions\n","for i, ax in enumerate(axes.flatten()):\n","    if i < len(predictions):\n","        label=prediction_names[i]\n","        # Plot the true values\n","        ax.plot(true_values, marker='o', label='True Value',linewidth=3, linestyle='--')\n","        # Plot the predictions\n","        ax.plot(predictions[i], label=label, marker='o')\n","        \n","\n","        \n","        # Set labels and title\n","        ax.set_xlabel('Image ID')\n","        ax.set_ylabel('Predictions')\n","        ax.set_title(label)\n","        \n","        # Rotate the x-axis tick labels vertically\n","        ax.tick_params(axis='x', rotation=90)\n","        \n","        # Add legend\n","        ax.legend()\n","    else:\n","        # Remove empty subplots\n","        ax.axis('off')\n","\n","# Adjust the spacing between subplots\n","plt.tight_layout()\n","\n","# Display the plot\n","plt.show() "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","# Define the number of rows and columns for subplots\n","num_rows = 4\n","num_cols = 5\n","\n","# Create subplots for comparing each model's predictions with the true values\n","fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 16))\n","\n","# Iterate through each model's predictions\n","for i, ax in enumerate(axes.flatten()):\n","    if i < len(predictions):\n","        label = prediction_names[i]\n","        \n","        # Get the corresponding true values and predictions\n","        true_vals = true_values[:len(predictions[i])]\n","        preds = predictions[i]\n","        \n","        # Compute the confusion matrix\n","        cm = confusion_matrix(true_vals, np.round(preds))\n","        \n","        # Create a heatmap for the confusion matrix\n","        sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', ax=ax)\n","        \n","        # Set labels and title\n","        ax.set_xlabel('Predicted')\n","        ax.set_ylabel('True')\n","        ax.set_title(label)\n","        \n","        # Rotate the x-axis tick labels vertically\n","        ax.tick_params(axis='x', rotation=90)\n","    else:\n","        # Remove empty subplots\n","        ax.axis('off')\n","\n","# Adjust the spacing between subplots\n","plt.tight_layout()\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","# Define the number of rows and columns for subplots\n","num_rows = 4\n","num_cols = 5\n","\n","# Create subplots for comparing each model's predictions with the true values\n","fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, 16))\n","\n","# Now we iterate through each model's predictions\n","for i, ax in enumerate(axes.flatten()):\n","    if i < len(predictions):\n","        label = prediction_names[i]\n","        \n","        true_vals = true_values[:len(predictions[i])]\n","        preds = predictions[i]\n","        \n","        # Compute the confusion matrix\n","        cm = confusion_matrix(true_vals, np.round(preds))\n","        \n","        # Normalize the confusion matrix\n","        cm_norm = cm / cm.sum(axis=1, keepdims=True)\n","        \n","        # Create a heatmap for the normalized confusion matrix\n","        sns.heatmap(cm_norm, annot=True, cmap='Blues', fmt='.2f', ax=ax)\n","        \n","        # Set labels and title\n","        ax.set_xlabel('Predicted')\n","        ax.set_ylabel('True')\n","        ax.set_title(label)\n","        \n","        # Rotate the x-axis tick labels vertically\n","        ax.tick_params(axis='x', rotation=90)\n","    else:\n","        # Remove empty subplots\n","        ax.axis('off')\n","        \n","plt.tight_layout()\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create an array of true labels from subDf_train dataframe\n","true_labels = np.array(subDf_train['isup_grade'])\n","\n","# Print the true_labels array\n","print(true_labels)\n","\n","# Import the cohen_kappa_score function from sklearn.metrics\n","from sklearn.metrics import cohen_kappa_score"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cm = confusion_matrix(FINAL, true_labels)\n","\n","# Plot confusion matrix as a heatmap\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n","plt.xlabel(\"Predicted Labels\")\n","plt.ylabel(\"True Labels\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Normalized Confusion Matrix Heatmap\n","plt.figure(figsize=(8, 6))\n","normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","sns.heatmap(normalized_cm, annot=True, fmt='.2f', cmap='Blues')\n","plt.title('Normalized Confusion Matrix - Multiclass Classification')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def calculate_prediction_percentages(predictions, actual_values): #Calculate the percentage of overdiagnosis vs underdiagnosis\n","    total_predictions = len(predictions)\n","    greater_count = 0\n","    lower_count = 0\n","\n","    for prediction, actual_value in zip(predictions, actual_values):\n","        if prediction > actual_value:\n","            greater_count += 1\n","        elif prediction < actual_value:\n","            lower_count += 1\n","\n","    greater_percentage = (greater_count / total_predictions) * 100\n","    lower_percentage = (lower_count / total_predictions) * 100\n","\n","    return greater_percentage, lower_percentage, greater_count, lower_count\n","\n","# Calculate the percentages and counts using the FINAL predictions and true labels\n","greater_percentage, lower_percentage, greater_count, lower_count = calculate_prediction_percentages(FINAL, true_labels)\n","\n","print(f\"Percentage of predictions greater than actual values: {greater_percentage}%; Absolute count: {greater_count}\")\n","print(f\"Percentage of predictions lower than actual values: {lower_percentage}%; Absolute count: {lower_count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def quadratic_weighted_kappa(y_hat, y):\n","    return cohen_kappa_score(y_hat, y, weights='quadratic')\n","\n","count = 0\n","for index, val in enumerate(true_labels):\n","    if FINAL[index] == val:\n","        count += 1\n","\n","print(f\"Accuracy Train is {(count / desiredNumberOfImages)* 100}\")\n","print(f'Kappa Train is {quadratic_weighted_kappa(FINAL, true_labels)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import confusion_matrix\n","\n","# Compute the confusion matrix\n","cm = confusion_matrix(true_labels, FINAL)\n","\n","# Initialize dictionaries to store TP, FP, TN, FN, and other metrics for each class\n","TP_dict = {}\n","FP_dict = {}\n","TN_dict = {}\n","FN_dict = {}\n","accuracy_dict = {}\n","precision_dict = {}\n","recall_dict = {}\n","specificity_dict = {}\n","f1_score_dict = {}\n","\n","# Calculate TP, FP, TN, FN, and other metrics for each class\n","for class_id in range(6):\n","    TP = cm[class_id, class_id]\n","    FP = np.sum(cm[:, class_id]) - TP\n","    TN = np.sum(cm) - (TP + FP + np.sum(cm[class_id, :]))\n","    FN = np.sum(cm[class_id, :]) - TP\n","\n","    TP_dict[class_id] = TP\n","    FP_dict[class_id] = FP\n","    TN_dict[class_id] = TN\n","    FN_dict[class_id] = FN\n","\n","    accuracy = (TP + TN) / (TP + FP + TN + FN)\n","    precision = TP / (TP + FP)\n","    recall = TP / (TP + FN)\n","    specificity = TN / (TN + FP)\n","    f1_score = (2 * precision * recall) / (precision + recall)\n","\n","    accuracy_dict[class_id] = accuracy\n","    precision_dict[class_id] = precision\n","    recall_dict[class_id] = recall\n","    specificity_dict[class_id] = specificity\n","    f1_score_dict[class_id] = f1_score\n","\n","# Print TP, FP, TN, FN, and other metrics for each class\n","for class_id in range(6):\n","    print(f\"Class {class_id}:\")\n","    print(\"True Positive (TP):\", round(TP_dict[class_id], 3))\n","    print(\"False Positive (FP):\", round(FP_dict[class_id], 3))\n","    print(\"True Negative (TN):\", round(TN_dict[class_id], 3))\n","    print(\"False Negative (FN):\", round(FN_dict[class_id], 3))\n","    print(\"Accuracy:\", round(accuracy_dict[class_id], 3))\n","    print(\"Precision:\", round(precision_dict[class_id], 3))\n","    print(\"Recall:\", round(recall_dict[class_id], 3))\n","    print(\"Specificity:\", round(specificity_dict[class_id], 3))\n","    print(\"F1 Score:\", round(f1_score_dict[class_id], 3))\n","    print()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from matplotlib.colors import LinearSegmentedColormap\n","\n","# Define the classes and metrics\n","classes = [0, 1, 2, 3, 4, 5]\n","metrics = ['Accuracy', 'Precision', 'Recall', 'Specificity', 'F1 Score']\n","class_labels = ['ISUP ' + str(class_id) for class_id in classes]  # Update the class labels\n","\n","\n","# Create a figure and axis for the star plot\n","fig, ax = plt.subplots(figsize=(8, 6), subplot_kw=dict(polar=True))\n","\n","# Plot the star plot for each class with the custom color\n","colors = [\"red\", \"green\", \"blue\", \"grey\", \"orange\", \"yellow\"]\n","for class_id, class_label, color in zip(classes, class_labels, colors):\n","    values = [\n","        accuracy_dict[class_id],\n","        precision_dict[class_id],\n","        recall_dict[class_id],\n","        specificity_dict[class_id],\n","        f1_score_dict[class_id]\n","    ]\n","    angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()\n","    values += values[:1]  # Repeat the first value to close the plot\n","    angles += angles[:1]  # Repeat the first angle to close the plot\n","    ax.plot(angles, values, label=class_label, color=color)  # Use the specific color\n","    ax.fill(angles, values, alpha=0.05)\n","\n","# Set the labels and title\n","ax.set_xticks(angles[:-1])\n","ax.set_xticklabels(metrics)\n","ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n","ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'])\n","ax.set_title('Star Plot of Metrics for Different ISUP Grades')\n","\n","# Add a legend\n","ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["overall_accuracy = np.mean(list(accuracy_dict.values()))\n","overall_precision = np.mean(list(precision_dict.values()))\n","overall_recall = np.mean(list(recall_dict.values()))\n","overall_specificity = np.mean(list(specificity_dict.values()))\n","overall_f1_score = np.mean(list(f1_score_dict.values()))\n","print(\"Overall Accuracy:\", overall_accuracy)\n","print(\"Overall Precision:\", overall_precision)\n","print(\"Overall Recall:\", overall_recall)\n","print(\"Overall Specificity:\", overall_specificity)\n","print(\"Overall F1 Score:\", overall_f1_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Calculating our expected number of unique draws\n","total_numbers = 10616\n","draw_size = 200\n","num_draws = 12\n","\n","expected_total_unique_objects = total_numbers * (1 - (1 - draw_size/total_numbers)**num_draws)\n","\n","print(\"Expected total number of unique objects:\", expected_total_unique_objects)"]},{"cell_type":"markdown","metadata":{},"source":["# Explainability"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","image_ids = np.array(subDf_train['image_id'].values)\n","true_values = subDf_train['isup_grade'].values\n","predictions = FINAL # Replace with your list of predictions\n","\n","# Set the x-axis positions\n","x = range(len(image_ids))\n","\n","# Create the line plots\n","plt.figure(figsize=(8, 6))\n","plt.plot(x, true_values, marker='o', label='True Value')\n","plt.plot(x, predictions, marker='o', label='Model Prediction')\n","\n","# Set the x-axis ticks and labels\n","plt.xlabel('Image ID')\n","plt.ylabel('ISUP Grade')\n","\n","# Set the title and legend\n","plt.title('True Value vs. Prediction')\n","plt.legend()\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# Create a new column 'predicted ISUP' in subDf_train\n","subDf_train['predicted_ISUP'] = [int(x) for x in FINAL] #it is to decide if we want to round up or round down the ISUP value:underdiagnose or over diagnose"]},{"cell_type":"markdown","metadata":{},"source":["## Visualization of histological sample and model prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import skimage.io\n","\n","def display_image_with_prediction(image_id, data_provider, gleason_score, true_value, prediction):\n","    image_path = '../input/prostate-cancer-grade-assessment/train_images/' + image_id + '.tiff'\n","    image = skimage.io.MultiImage(image_path)[1]\n","    \n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(image)\n","    plt.title(f\"Image ID: {image_id} | Data Provider: {data_provider} | Gleason Score: {gleason_score} | True Value: {true_value} | Prediction: {prediction}\")\n","    plt.axis('off')\n","    plt.show()\n","\n","# Get the first 5 image IDs, Gleason scores, true values, and predictions\n","image_ids = subDf_train['image_id'].values[:5]\n","gleason_scores = subDf_train['gleason_score'].values[:5]\n","data_providers = subDf_train['data_provider'].values[:5]\n","true_values = subDf_train['isup_grade'].values[:5]\n","predictions = subDf_train['predicted_ISUP'].values[:5]\n","\n","# Display images and predictions\n","for image_id, gleason_score, data_provider, true_value, prediction in zip(image_ids, gleason_scores, data_providers, true_values, predictions):\n","    display_image_with_prediction(image_id, data_provider, gleason_score, true_value, prediction)"]},{"cell_type":"markdown","metadata":{},"source":["## Visualization with mask overlay"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def overlay_mask_on_slide(slide, mask, center='radboud', alpha=0.8, max_size=(800, 800), title=''):\n","    \"\"\"Show a mask overlayed on a slide.\"\"\"\n","    \n","    if center not in ['radboud', 'karolinska']:\n","        raise Exception(\"Unsupported palette, should be one of [radboud, karolinska].\")\n","    \n","    # Load data from the highest level\n","    slide_data = slide.read_region((0, 0), slide.level_count - 1, slide.level_dimensions[-1])\n","    mask_data = mask.read_region((0, 0), mask.level_count - 1, mask.level_dimensions[-1])\n","    \n","    # Mask data is present in the R channel\n","    mask_data = mask_data.split()[0]\n","    \n","    # Create alpha mask\n","    alpha_int = int(round(255 * alpha))\n","    if center == 'radboud':\n","        alpha_content = np.less(mask_data.split()[0], 2).astype('uint8') * alpha_int + (255 - alpha_int)\n","    elif center == 'karolinska':\n","        alpha_content = np.less(mask_data.split()[0], 1).astype('uint8') * alpha_int + (255 - alpha_int)\n","    \n","    alpha_content = Image.fromarray(alpha_content)\n","    preview_palette = np.zeros(shape=768, dtype=int)\n","    \n","    if center == 'radboud':\n","        # Mapping: {0: background, 1: stroma, 2: benign epithelium, 3: Gleason 3, 4: Gleason 4, 5: Gleason 5}\n","        preview_palette[0:18] = (np.array([0, 0, 0, 0.5, 0.5, 0.5, 0, 1, 0, 1, 1, 0.7, 1, 0.5, 0, 1, 0, 0]) * 255).astype(int)\n","    elif center == 'karolinska':\n","        # Mapping: {0: background, 1: benign, 2: cancer}\n","        preview_palette[0:9] = (np.array([0, 0, 0, 0, 1, 0, 1, 0, 0]) * 255).astype(int)\n","    \n","    mask_data.putpalette(data=preview_palette.tolist())\n","    mask_rgb = mask_data.convert(mode='RGB')\n","    \n","    overlayed_image = Image.composite(image1=slide_data, image2=mask_rgb, mask=alpha_content)\n","    overlayed_image.thumbnail(size=max_size, resample=0)\n","    \n","    title= f\"Image ID: {image_id} | Data Provider: {data_provider} | Gleason Score: {gleason_score} | True Value: {true_value} | Prediction: {prediction}\"\n","    \n","    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n","    fig.suptitle(title, fontsize=14, fontweight='bold')\n","    \n","    axes[0].imshow(slide_data)\n","    axes[0].set_title('Slide Image')\n","    axes[0].axis('off')\n","    \n","    axes[1].imshow(overlayed_image)\n","    axes[1].set_title('Overlayed Image')\n","    axes[1].axis('off')\n","    \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import openslide\n","from PIL import Image\n","import random\n","\n","data_dir = '/kaggle/input/prostate-cancer-grade-assessment/train_images'\n","mask_dir = '/kaggle/input/prostate-cancer-grade-assessment/train_label_masks'\n","\n","# Select 5 random samples\n","random_samples = subDf_train.sample(5)\n","\n","# Iterate over each random sample\n","for index, row in random_samples.iterrows():\n","    image_id = row['image_id']\n","    data_provider = row['data_provider']\n","    gleason_score = row['gleason_score']\n","    true_value = row['isup_grade']\n","    prediction = row['predicted_ISUP']\n","    \n","    # Set the file paths for the slide and mask\n","    slide_path = os.path.join(data_dir, f'{image_id}.tiff')\n","    mask_path = os.path.join(mask_dir, f'{image_id}_mask.tiff')\n","    \n","    # Overlay the mask on the slide for radboud data provider\n","    if data_provider == 'radboud':\n","        slide = openslide.OpenSlide(slide_path)\n","        mask = openslide.OpenSlide(mask_path)\n","        overlay_mask_on_slide(slide, mask, center='radboud', title=f\"Image ID: {image_id} | Data Provider: {data_provider} | Gleason Score: {gleason_score} | True Value: {true_value} | Prediction: {prediction}\")\n","        \n","    # Overlay the mask on the slide for karolinska data provider\n","    elif data_provider == 'karolinska':\n","        slide = openslide.OpenSlide(slide_path)\n","        mask = openslide.OpenSlide(mask_path)\n","        overlay_mask_on_slide(slide, mask, center='karolinska', alpha=0.5, title=f\"Image ID: {image_id} | Data Provider: {data_provider} | Gleason Score: {gleason_score} | True Value: {true_value} | Prediction: {prediction}\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"}},"nbformat":4,"nbformat_minor":4}
